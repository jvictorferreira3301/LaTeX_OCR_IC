{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jvictorferreira3301/LaTeX_OCR_IC/blob/main/latexOCR.ipynb\" target=\"_parent\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"height: 27px; margin-right: 10px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LATex OCR üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaTeX-OCR is an advanced application that combines OCR and Transformers technologies to automate the conversion of mathematical expressions into LaTeX code, bringing efficiency to academic and scientific activities. Although it still faces challenges with complex data and manuscripts, it represents an important evolution in the use of AI to facilitate the digitization and editing of complex mathematical content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <figure style=\"margin-right: 10px; text-align: center;\">\n",
    "        <img src=\"./assets/wf.png\" width=\"auto\" height=\"auto\" style=\"display: flex; margin:0\">\n",
    "        <figcaption>Fig. 1 - Flowchart of application. </figcaption>\n",
    "    </figure>\n",
    "    <figure style=\"text-align: center;\">\n",
    "        <img src=\"./assets/gif.gif\" width=\"auto\" height=\"auto\" tyle=\"display: flex; margin:10px\">\n",
    "        <figcaption> Fig. 2 - Example of use with GUI.</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "        <img src=\"./assets/timeline.svg\" width=\"auto\" height=\"auto\">\n",
    "        <figcaption>Fig. 3 - Timeline of models.</figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Optical Character Recognition (OCR):** is the technology used to identify and extract text from images. In applications like LaTeX-OCR, OCR needs to go beyond simple text reading and recognize the hierarchical structure of mathematical expressions.\n",
    "\n",
    "- **Image Tokenization:** Tokenization is the process of breaking data into smaller units, called tokens, that can be processed individually. In traditional text OCR, each character or word may be a token; in images of equations, each part of the expression (symbol, operator, or substructure) can be tokenized.\n",
    "\n",
    "- **Attention and Self-Attention:** Attention is a mechanism that allows the model to ‚Äúfocus‚Äù on specific parts of the data when making decisions. Self-attention enables each part of the sequence (or image) to consider all other parts, capturing complex dependencies.\n",
    "\n",
    "- **Positional Encoding**: In neural networks, especially Transformers, positional encoding is used to preserve the order of tokens, as the model itself does not maintain an explicit sequence.\n",
    "\n",
    "- **Transformers and Encoder-Decoder Networks:** Transformers are neural networks that use attention mechanisms to process data sequences. Encoder-Decoder models are a common Transformer architecture for translating input sequences to output sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the foundation, we will train the model using our dataset extracted from the LaTeX files of the following books by Prof. Aldebaro Klautau.\n",
    "\n",
    "- _Digital Signal Processing with Python, Matlab or Octave_\n",
    "- _Digital Communications with Python, Matlab or Octave_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Extract equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all equations from .tex files to a single .tex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% ChatGPT :D\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from wand.image import Image\n",
    "from wand.color import Color\n",
    "import os\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def load_macros(macros_file):\n",
    "    \"\"\"Reads macros from a LaTeX macros file and returns a dictionary of replacements.\"\"\"\n",
    "    macros = {}\n",
    "    macro_pattern = r'\\\\(?:def|newcommand)\\s*\\\\(\\w+)\\s*(?:\\[(.*?)\\])?\\s*(\\{(.*)\\})'\n",
    "    \n",
    "    with open(macros_file, 'r') as file:\n",
    "        for line in file:\n",
    "            match = re.match(macro_pattern, line.strip())\n",
    "            if match:\n",
    "                command, _, definition, inside_def = match.groups()\n",
    "\n",
    "                macros[rf'\\\\{command}'] = inside_def  # Store macro with regex-escaped backslash\n",
    "\n",
    "                # print(f'{command} {inside_def}')\n",
    "            \n",
    "    return macros\n",
    "\n",
    "def replacement_function(match, definition, param_mapping):\n",
    "    if len(param_mapping) > 0:\n",
    "        print(f'{match} {definition} {param_mapping}')\n",
    "\n",
    "def replace_macros(equations, macros):\n",
    "    \"\"\"Replaces macros in equations using the given macros dictionary, ensuring standalone replacements.\"\"\"\n",
    "    for i, equation in enumerate(equations):\n",
    "        for macro, definition in macros.items():\n",
    "            # Replace each macro with its definition\n",
    "            # This regex captures the argument inside the curly braces\n",
    "            equation = re.sub(\n",
    "                rf'(?<!\\\\)({macro})\\{{(.*?)\\}}',  # Match macro and its argument\n",
    "                lambda match: definition.replace('#1', match.group(2).replace('$', '')),  # Replace #1 with the captured argument\n",
    "                equation\n",
    "            )\n",
    "          \n",
    "\n",
    "        equations[i] = equation\n",
    "    return equations\n",
    "\n",
    "def replace_macros2(equations, macros):\n",
    "    \"\"\"Replaces macros in equations using the given macros dictionary, ensuring standalone replacements.\"\"\"\n",
    "    for i, equation in enumerate(equations):\n",
    "        for macro, definition in macros.items():\n",
    "            # Check if the definition contains placeholders\n",
    "            param_pattern = re.findall(r'#(\\d+)', definition)\n",
    "\n",
    "            # Create a mapping for parameters if there are placeholders\n",
    "            param_mapping = {}\n",
    "            for j in range(len(param_pattern)):\n",
    "                param_index = int(param_pattern[j]) - 1  # Convert to 0-based index\n",
    "                # Capture parameters from the equation based on their positions\n",
    "                matches = re.findall(r'(\\{.*?\\}|\\S+)', equation)  # Capture everything in braces and standalone words\n",
    "                if param_index < len(matches):\n",
    "                    param_mapping[f'#{j + 1}'] = matches[param_index]\n",
    "\n",
    "            # Replace each macro using a lambda to avoid escape sequence issues\n",
    "            equation = re.sub(\n",
    "                rf'(?<!\\\\)({macro})(?![a-zA-Z0-9])',\n",
    "                lambda match: re.sub(\n",
    "                    r'(#\\d+)',\n",
    "                    lambda m: param_mapping.get(m.group(0), m.group(0)),  # Substitute placeholders with mapped values\n",
    "                    definition\n",
    "                ),\n",
    "                equation\n",
    "            )\n",
    "        equations[i] = equation\n",
    "    return equations\n",
    "\n",
    "def extract_equations(input_tex_file, macros_file):\n",
    "    # Load macros from macros_file\n",
    "    macros = load_macros(macros_file)\n",
    "    \n",
    "    # Regular expressions to match equations\n",
    "    equation_patterns = [\n",
    "        # r'\\$\\$(.*?)\\$\\$',            # Inline equations with $$ ... $$\n",
    "        # r'\\$(.*?)\\$',                # Inline equations with $ ... $\n",
    "        r'\\\\\\[(.*?)\\\\\\]',            # Displayed equations with \\[ ... \\]\n",
    "        r'\\\\begin\\{equation\\}(.*?)\\\\end\\{equation\\}',  # equation environment\n",
    "        # r'\\\\begin\\{align\\}(.*?)\\\\end\\{align\\}'         # align environment\n",
    "    ]\n",
    "    \n",
    "    # Read the input LaTeX file\n",
    "    with open(input_tex_file, 'r') as file:\n",
    "        tex_content = file.read()\n",
    "    \n",
    "    # Find all matches for each pattern\n",
    "    equations = []\n",
    "    for pattern in equation_patterns:\n",
    "        matches = re.findall(pattern, tex_content, re.DOTALL)\n",
    "        equations.extend(matches)\n",
    "    \n",
    "    # Replace macros in equations\n",
    "    equations = replace_macros(equations, macros)\n",
    "    equations = replace_macros2(equations, macros)\n",
    "\n",
    "    return equations\n",
    "    \n",
    "tex_files_folder = 'bootor_tex'\n",
    "\n",
    "output_tex_file = f'outputs/extracted_equations.tex'\n",
    "\n",
    "macros_file = 'macros/macros.tex'\n",
    "\n",
    "total_equations = 0\n",
    "\n",
    "if not os.path.exists('outputs'):\n",
    "        os.mkdir('outputs')\n",
    "\n",
    "# Write equations to a new .tex file\n",
    "with open(output_tex_file, 'w') as output_file:\n",
    "    output_file.write('\\\\documentclass{article}\\n')\n",
    "    output_file.write('\\\\usepackage{amsmath}\\n')\n",
    "    output_file.write('\\\\usepackage{amssymb}\\n')\n",
    "    output_file.write('\\\\begin{document}\\n')\n",
    "\n",
    "    for subfolder in Path(tex_files_folder).glob('*'):\n",
    "\n",
    "        for file in subfolder.glob('*'):\n",
    "            equations = extract_equations(file, macros_file)\n",
    "\n",
    "            # Write each extracted equation\n",
    "            for eq in equations:\n",
    "                output_file.write('\\n\\\\begin{equation}\\n')\n",
    "                output_file.write(eq.strip())\n",
    "                output_file.write('\\n\\\\end{equation}\\n')\n",
    "\n",
    "            print(f\"Extracted {len(equations)} equations from {file}.\")\n",
    "            total_equations = total_equations + len(equations)\n",
    "\n",
    "    # Write end of the document\n",
    "    output_file.write('\\\\end{document}\\n')\n",
    "\n",
    "print(f'Found {total_equations} equations in the folder {tex_files_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Equations to .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse extracted equations to a .txt where each line will be a different equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_equations(input_file, output_file):\n",
    "    # Regular expression for LaTeX equations in \\begin{equation} ... \\end{equation}, ignoring \\label{}\n",
    "    equation_pattern = r'\\\\begin\\{equation\\}(.+?)\\\\end\\{equation\\}'\n",
    "    label_pattern = r'\\\\label\\{[^}]*\\}'  # Pattern to match and remove labels\n",
    "\n",
    "    # Read input file and extract equations\n",
    "    with open(input_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "        # Find all matches for the equation pattern\n",
    "        equations = re.findall(equation_pattern, content, re.DOTALL)\n",
    "        \n",
    "        # Process each equation to remove labels and convert to a single line\n",
    "        cleaned_equations = []\n",
    "        for eq in equations:\n",
    "            cleaned_eq = re.sub(label_pattern, '', eq)  # Remove label\n",
    "\n",
    "            eq_lines = cleaned_eq.split('\\n')\n",
    "\n",
    "            poped = 0\n",
    "            for i in range(len(eq_lines)):                \n",
    "                if eq_lines[i - poped].replace(' ', '').startswith('%'):\n",
    "                    eq_lines.pop(i - poped)\n",
    "                    poped += 1\n",
    "\n",
    "                if (len(eq_lines[i - poped].split('%')) > 1):\n",
    "                    eq_lines[i - poped] = eq_lines[i - poped].split('%')[0]\n",
    "\n",
    "            cleaned_eq = ''.join(eq_lines)\n",
    "\n",
    "            cleaned_eq = re.sub(r'\\s+', ' ', cleaned_eq)  # Replace multiple spaces/newlines with a single space\n",
    "            cleaned_eq = cleaned_eq.strip()  # Trim leading and trailing spaces\n",
    "            cleaned_equations.append(cleaned_eq)\n",
    "\n",
    "    # Write each cleaned equation to a new line in the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        total_equations = 0\n",
    "        for equation in cleaned_equations:\n",
    "            if len(equation) > 0:\n",
    "                file.write(equation + '\\n')\n",
    "                total_equations += 1\n",
    "\n",
    "        print(f'Extracted {total_equations} usable equations!')\n",
    "\n",
    "# Usage\n",
    "input_tex_file = 'outputs/extracted_equations.tex'\n",
    "output_txt_file = 'outputs/extracted_equations.txt'\n",
    "extract_equations(input_tex_file, output_txt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Generate PDFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compile extracted equations to PDF (each equation generates a different file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_equations(input_txt_file):\n",
    "    \"\"\"Extract equations from the input .txt file, each line being an equation.\"\"\"\n",
    "    equations = []\n",
    "    with open(input_txt_file, 'r') as file:\n",
    "        # Read each line and strip any extra whitespace\n",
    "        for line in file:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:  # Only add non-empty lines\n",
    "                equations.append(stripped_line)\n",
    "    return equations\n",
    "\n",
    "def create_tex_file(equation, index):\n",
    "    \"\"\"Create a .tex file for the given equation.\"\"\"\n",
    "    tex_content = r\"\"\"\\documentclass{article}\n",
    "\\usepackage{amsmath}\n",
    "\\usepackage{amssymb}\n",
    "\\usepackage{xcolor}\n",
    "\\begin{document}\n",
    "\\pagestyle{empty}\n",
    "\\begin{equation*}\n",
    "\"\"\" + equation + r\"\"\"\n",
    "\\end{equation*}\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    file_name = f\"{str(index).zfill(5)}.tex\"\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(tex_content)\n",
    "    return file_name\n",
    "\n",
    "def compile_tex_file(tex_file):\n",
    "    \"\"\"Compile the .tex file using XeLaTeX.\"\"\"\n",
    "    subprocess.run(['xelatex', tex_file], check=True)\n",
    "\n",
    "def compile_tex_files(tex_files):\n",
    "    \"\"\"Compile multiple .tex files concurrently.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(compile_tex_file, tex_files)\n",
    "\n",
    "def main(input_tex_file):\n",
    "    if not os.path.exists('outputs/pdfs'):\n",
    "        os.makedirs('outputs/pdfs')\n",
    "\n",
    "    equations = extract_equations(input_tex_file)\n",
    "\n",
    "    tex_files = []\n",
    "    for index, equation in enumerate(equations):\n",
    "        tex_file = create_tex_file(equation.strip(), index)\n",
    "        tex_files.append(tex_file)\n",
    "\n",
    "    # Compile all .tex files concurrently\n",
    "    compile_tex_files(tex_files)\n",
    "\n",
    "    # Move PDFs to the output directory and clean up auxiliary files\n",
    "    for tex_file in tex_files:\n",
    "        pdf_file = Path(tex_file).with_suffix('.pdf')\n",
    "        if pdf_file.exists():\n",
    "            pdf_file.rename(Path('outputs/pdfs') / pdf_file.name)\n",
    "            # Clean up auxiliary files\n",
    "            os.remove(tex_file)\n",
    "            os.remove(tex_file.replace('.tex', '.aux'))\n",
    "            os.remove(tex_file.replace('.tex', '.log'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_tex_file = 'outputs/extracted_equations.txt'\n",
    "    main(input_tex_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. PDF to PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert PDF files to PNG images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = 'outputs/pdfs'\n",
    "TRG_PATH = 'outputs/images'\n",
    "RESOLUTION = 200  # lower resolution for faster processing\n",
    "\n",
    "def convert_pdf_to_png(pdf_path):\n",
    "    output_path = Path(TRG_PATH) / f\"{pdf_path.stem}.png\"\n",
    "    with Image(filename=str(pdf_path), resolution=RESOLUTION) as img:\n",
    "        img.format = 'png'\n",
    "        img.depth = 8\n",
    "        img.trim(color=Color('rgba(0,0,0,0)'), fuzz=0)  # Trim transparent areas\n",
    "        img.background_color = Color('white')  # Set white background\n",
    "        img.alpha_channel = 'remove'           # Remove transparency\n",
    "        img.save(filename=str(output_path))\n",
    "    print(f\"Converted {pdf_path} to {output_path}\")\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists('outputs/images'):\n",
    "        os.mkdir('outputs/images')\n",
    "\n",
    "    pdf_dir = Path(SRC_PATH)\n",
    "    pdf_files = list(pdf_dir.glob('*.pdf'))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(convert_pdf_to_png, pdf_files)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Perfomance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
